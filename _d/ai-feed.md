---
layout: post
title: "AI Feed — Curated Reading Through Claude"
permalink: /ai-feed
redirect_from:
  - /ai-reading
  - /curated-feed
tags:
  - ai
  - productivity
---

Pretty common: I get a bag of links — a newsletter, a Twitter thread, a friend's Slack message. I open them all in tabs, skim, close most, and forget. Maybe one in ten sticks. The rest vanish into the consumption void.

This is my attempt to fix that using AI as a reading partner. Instead of the tab-explosion-and-forget cycle, I paste links into Claude Code, which fetches, summarizes, predicts what I'll like, and captures everything here. Later, when I actually read the good ones, I come back and debrief — recording what resonated and what didn't.

It's [GTD](/gtd) capture meets AI triage. And unlike passive consumption, this process produces something: a public record of what I read, what I think about it, and how my taste evolves. That makes it [production, not consumption](/produce-consume).

## What I Gravitate Toward

_This section evolves as patterns emerge from what I read and skip._

Still calibrating — check back after a few sessions.

## Feed

### 2026-03-01

_Source: [Joy & Curiosity #76](https://registerspill.thorstenball.com/p/joy-and-curiosity-76) by Thorsten Ball_

- **[Cognitive Debt](https://margaretstorey.com/blog/2026/02/09/cognitive-debt/)** — Margaret-Anne Storey on losing understanding when AI generates code
  - _Summary_: Velocity without understanding is not sustainable. As AI accelerates development, the real risk isn't technical debt but cognitive debt — teams losing shared understanding of what software does and why. Advocates pair programming, refactoring, and TDD to maintain collective "theory" of a system.
  - _Why I'd like it_: You coined "The Willison Pattern" and built /explainers around this exact concept. This is your home turf.
  - _Cross-links_: [Explainers](/explainers), [AI Native Manager](/ai-native-manager), [CHOW](/chow), [Pet Projects](/pet-projects)
  - _Tags_: #cognitive-debt #ai-practice #craft
  - _Reaction_:
- **[How We Hire Engineers When AI Writes Our Code](https://www.tolans.com/relay/how-we-hire-engineers-when-ai-writes-our-code)** — Dan Federman on rethinking technical interviews
  - _Summary_: Traditional technical interviews are obsolete. Tolan redesigned hiring to test judgment, reasoning, and architecture by having candidates build real features with AI tools — testing what actually matters now, not algorithm memorization.
  - _Why I'd like it_: Direct extension of your /ai-hiring post. Real company doing it, not just theorizing.
  - _Cross-links_: [AI Hiring](/ai-hiring), [Agency](/agency), [AI Native Manager](/ai-native-manager)
  - _Tags_: #ai-hiring #management #craft
  - _Reaction_:
- **[747s and Coding Agents](https://carlkolon.com/2026/02/27/engineering-747-coding-agents/)** — Carl Kolon on AI eroding deep understanding
  - _Summary_: AI agents boost output but erode deep understanding — like a 747 pilot who stops learning because the plane flies itself. Programmers risk becoming operators, not engineers, if they don't deliberately maintain domain knowledge through hands-on problem-solving.
  - _Why I'd like it_: Maps directly to your "Don't stop thinking" and "Deep Blue" sections in /ai-native-manager.
  - _Cross-links_: [AI Native Manager](/ai-native-manager), [CHOP](/chop)
  - _Tags_: #skill-atrophy #ai-practice #contrarian
  - _Reaction_:
- **[Nobody Knows How the Whole System Works](https://surfingcomplexity.blog/2026/02/08/nobody-knows-how-the-whole-system-works/)** — Lorin Hochstein on irreducible complexity
  - _Summary_: Complete comprehension across all layers of modern systems is impossible — a reality AI is making more acute, not fundamentally changing. Synthesizes perspectives from Simon Wardley, Adam Jacob, and others to argue it's dangerous to build without understanding, but full understanding is a myth.
  - _Why I'd like it_: Systems thinking is your jam. Connects to your complexity-per-person concerns in /ai-native-manager.
  - _Cross-links_: [AI Native Manager](/ai-native-manager), [Explainers](/explainers)
  - _Tags_: #complexity #systems-thinking #cognitive-debt
  - _Reaction_:
- **[Building An Elite AI Engineering Culture](https://www.cjroth.com/blog/2026-02-18-building-an-elite-engineering-culture)** — Chris Roth on AI amplifying organizational strengths
  - _Summary_: AI amplifies existing organizational strengths and weaknesses — creating a 5.7x efficiency gap between disciplined teams and the rest. Without engineering rigor (specs, testing, reviews), AI tools just make your problems louder.
  - _Why I'd like it_: Relevant to your management writing, concrete data on the amplification effect.
  - _Cross-links_: [AI Native Manager](/ai-native-manager), [CHOP](/chop), [AI Hiring](/ai-hiring)
  - _Tags_: #management #ai-practice #engineering-culture
  - _Reaction_:
- **[Scattered Thoughts on LLM Tools](https://www.jmduke.com/posts/five-observations-ai-tools.html)** — Justin Duke on practical AI tool challenges
  - _Summary_: LLM tools are improving incrementally but remain fundamentally flawed as software products. The real bottleneck isn't AI capability but infrastructure — sandboxed environments, data integration, feedback loops, and systemic process gaps.
  - _Why I'd like it_: Practitioner perspective on the gap between AI hype and actual tool experience. Grounded.
  - _Cross-links_: [CHOP](/chop), [AI Cockpit](/ai-cockpit), [How Igor CHOPs](/how-igor-chops)
  - _Tags_: #ai-tools #practitioner #infrastructure
  - _Reaction_:
- **[Cloudflare vinext](https://blog.cloudflare.com/vinext/)** — Steve Faulkner on one engineer rebuilding Next.js with AI
  - _Summary_: One engineer rebuilt Next.js as "vinext" in a week for $1,100 in AI tokens. AI doesn't need the intermediate abstractions humans created to manage complexity — many existing software layers will become obsolete.
  - _Why I'd like it_: Great case study of AI productivity, but more "look what AI can do" than practitioner reflection.
  - _Cross-links_: [CHOP](/chop), [AI Developer](/ai-developer), [Produce vs Consume](/produce-consume)
  - _Tags_: #ai-productivity #vibe-coding #case-study
  - _Reaction_:
- **[The Happiest I've Ever Been](https://ben-mini.com/2026/the-happiest-ive-ever-been)** — Ben Wallace on finding joy outside career
  - _Summary_: True happiness comes from activities aligned with intrinsic values, not career prestige. Coaching youth basketball fulfilled him more than his corporate job. Tech workers should question Silicon Valley's propaganda about professional value equaling personal worth.
  - _Why I'd like it_: Connects to your joy/meaning writing but not AI-specific.
  - _Cross-links_: [Joy](/joy), [Produce vs Consume](/produce-consume)
  - _Tags_: #happiness #meaning #anti-hustle
  - _Reaction_:
- **[The Very Hungry Caterpillar Design Analysis](https://lookingatpicturebooks.com/p/the-very-hungry-caterpillar)** — Mac Barnett & Jon Klassen on Eric Carle's craft
  - _Summary_: Carle's book succeeds through masterful control of color, shape, and die-cut innovation — not expressive character design. Deliberately stripped away emotional facial features to create warmth, bridging toys and books while carrying bittersweet melancholy about transformation.
  - _Why I'd like it_: Beautiful craft analysis but tangential to your usual themes.
  - _Cross-links_: [AI Journal](/ai-journal)
  - _Tags_: #design #craft #children
  - _Reaction_:
- **[What Claude Code Actually Chooses](https://amplifying.ai/research/claude-code-picks)** — Research on AI code assistant tool selection
  - _Summary_: (Already read — Igor noted it was excellent)
  - _Why I'd like it_: Directly relevant to your daily CHOP workflow.
  - _Cross-links_: [CHOP](/chop), [How Igor CHOPs](/how-igor-chops), [AI Cockpit](/ai-cockpit)
  - _Tags_: #ai-tools #claude #research
  - _Reaction_: Already read — excellent.
